{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c1b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9e8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0.dev20220408+cu113'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba51b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ab16e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/transformers/models/auto/modeling_auto.py:907: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead,AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5573542f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"t5large_2e.pt\")) #(\"t5-smalltrain_acc4.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5575cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7953f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets_grammar as dg\n",
    "from defaults import train_config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "506304cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = train_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b36fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-e2d071caf158a2c7\n",
      "Reusing dataset csv (/home/ubuntu/.cache/huggingface/datasets/csv/default-e2d071caf158a2c7/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabe68b166c844ab99f00b87a23747ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2988\n",
      "using dataset datasets_grammar/grammar_validation.csv\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dg.get_dataset(tokenizer, cfg.dataset_test, 512, 512, True)\n",
    "print(len(test_dataset))\n",
    "print(f\"using dataset {cfg.dataset_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "22eda70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_step(model, batch):\n",
    "    #print(batch.keys())\n",
    "    curr_loss = torch.zeros(3)#.to(\"cuda:0\")\n",
    "    for key in batch.keys():\n",
    "        #batch[key] = batch[key].to(\"cuda:0\")\n",
    "        output = model(\n",
    "                input_ids=batch[\"source_ids\"],\n",
    "                attention_mask=batch[\"source_mask\"],\n",
    "                labels=batch[\"target_ids\"],\n",
    "            )\n",
    "        curr_loss[0] += output[\"loss\"].item()  # sum up batch loss\n",
    "        curr_loss[1] +=len(batch)\n",
    "        #print(curr_loss)\n",
    "        #pred = output.logits.argmax(\n",
    "         #       dim=1, keepdim=True\n",
    "         #   )  # get the index of the max log-probability\n",
    "        #print(pred)\n",
    "        #curr_loss[1] += pred.eq(batch[\"target_ids\"].view_as(pred)).sum().item()\n",
    "        #curr_loss[2] += len(batch)\n",
    "        #print(output)\n",
    "        #loss = 0\n",
    "    #loss = model(**data)\n",
    "    return curr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dbd8f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = torch.zeros(3)\n",
    "    for batch_index, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            loss = validate_one_step(model, data)\n",
    "        total_loss += loss\n",
    "        \n",
    "        print(total_loss[0]/total_loss[1])\n",
    "        if batch_index > 4:\n",
    "            break\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5a3ab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42254b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.to(\"cuda:0\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e557bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0040)\n",
      "tensor(0.0031)\n",
      "tensor(0.0027)\n",
      "tensor(0.0046)\n",
      "tensor(0.0042)\n",
      "tensor(0.0040)\n"
     ]
    }
   ],
   "source": [
    "test_loss = validate_one_epoch(model,test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1256911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3809, 96.0000,  0.0000])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "daaeedb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0040)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss[0]/test_loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "21154030",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"The cherry blossoms was so pretty\"\n",
    "test2 = \"Our dogs is running in the park.\"\n",
    "test3 = \"Their the ones who made a mistake.\"\n",
    "test4 = \"Its cold outside today.\"\n",
    "test5 = \"The baby was held by its mother.\"\n",
    "test6 = \"The book on AI really effected me.\"\n",
    "test7= \"The children love eating, coloring, and to play with their toys.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2eb715dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test7 #\"I is reading about AI articles \"\n",
    "inputs = tokenizer(\"grammar:\"+text, truncation=True, return_tensors='pt')\n",
    "\n",
    "output = model.generate(inputs['input_ids'], num_beams=5, max_length=512, early_stopping=True)\n",
    "correction=tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "result=(\"\".join(correction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea2d2b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The children love eating, coloring, and to play with their toys.\n",
      "\n",
      "corrected: The children love eating, coloring, and playing with their toys.\n"
     ]
    }
   ],
   "source": [
    "print(f\"input: {text}\\n\")\n",
    "print(f\"corrected: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p38)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
