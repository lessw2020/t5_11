{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "92c1b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "de9e8d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.0.dev20220408+cu113'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71808eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.defaults import train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a9d0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = train_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6dd2d2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba51b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"t5-small\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ab16e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead,AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5573542f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"t5large_2e.pt\")) #(\"t5-smalltrain_acc4.pt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5575cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7953f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets_grammar as dg\n",
    "from config.defaults import train_config\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "506304cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = train_config()\n",
    "torch.cuda.set_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45b36fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-cd2f820f78130da3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset csv/default to /home/ubuntu/.cache/huggingface/datasets/csv/default-cd2f820f78130da3/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1da95de5d58f4d5bb9cc9db4a7c83fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55255197b8ef471686c4d191dc8c05d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset csv downloaded and prepared to /home/ubuntu/.cache/huggingface/datasets/csv/default-cd2f820f78130da3/0.0.0/433e0ccc46f9880962cc2b12065189766fbb2bee57a221866138fb9203c83519. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3c4154f61e847d98c6af69a0a3d44d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2988\n",
      "using dataset datasets_grammar/grammar_validation.csv\n"
     ]
    }
   ],
   "source": [
    "test_dataset = dg.get_dataset(tokenizer, cfg.dataset_test, 512, 512, True)\n",
    "print(len(test_dataset))\n",
    "print(f\"using dataset {cfg.dataset_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "22eda70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_step(model, batch):\n",
    "    #print(batch.keys())\n",
    "    curr_loss = torch.zeros(3)#.to(\"cuda:0\")\n",
    "    for key in batch.keys():\n",
    "        #print(f\"batch key = {key}\")\n",
    "        batch[key] = batch[key].to(\"cuda:0\")\n",
    "        \n",
    "    output = model(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            labels=batch[\"target_ids\"],\n",
    "        )\n",
    "    curr_loss[0] += output[\"loss\"].item()  # sum up batch loss\n",
    "    curr_loss[1] +=len(batch)\n",
    "        #print(curr_loss)\n",
    "        #pred = output.logits.argmax(\n",
    "         #       dim=1, keepdim=True\n",
    "         #   )  # get the index of the max log-probability\n",
    "        #print(pred)\n",
    "        #curr_loss[1] += pred.eq(batch[\"target_ids\"].view_as(pred)).sum().item()\n",
    "        #curr_loss[2] += len(batch)\n",
    "        #print(output)\n",
    "        #loss = 0\n",
    "    #loss = model(**data)\n",
    "    return curr_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dbd8f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_one_epoch(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = torch.zeros(3)\n",
    "    for batch_index, data in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            loss = validate_one_step(model, data)\n",
    "        total_loss += loss\n",
    "        \n",
    "        print(total_loss[0]/total_loss[1])\n",
    "        if batch_index > 4:\n",
    "            break\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c6646142",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_one_epoch(model, dataloader, device):\n",
    "    ddp_loss = torch.zeros(3).to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            for key in batch.keys():\n",
    "                batch[key] = batch[key].to(\"cuda:0\")\n",
    "            output = model(\n",
    "                input_ids=batch[\"source_ids\"],\n",
    "                attention_mask=batch[\"source_mask\"],\n",
    "                labels=batch[\"target_ids\"],\n",
    "            )\n",
    "            ddp_loss[0] += output[\"loss\"].item()  # sum up batch loss\n",
    "            ddp_loss[1] += len(batch)\n",
    "            #ddp_loss[0] += \n",
    "            #pred = output.logits.argmax(\n",
    "             #   dim=1, keepdim=True\n",
    "            #)  # get the index of the max log-probability\n",
    "            #print(f\"pred = {pred.shape}\\n{pred}\")\n",
    "            #ddp_loss[1] += pred.eq(batch[\"target_ids\"].view_as(pred)).sum().item()\n",
    "            \n",
    "\n",
    "    test_loss = ddp_loss[0] / ddp_loss[1]\n",
    "    print(f\"Total test loss: {test_loss}\")\n",
    "    return test_loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5a3ab31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "42254b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.cuda.set_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e557bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total test loss: 3.035662889480591\n"
     ]
    }
   ],
   "source": [
    "test_loss = test_one_epoch(model,test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1256911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0357, device='cuda:0')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daaeedb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.4083)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss[0]/test_loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "21154030",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"The cherry blossoms was so pretty\"\n",
    "test2 = \"Our dogs is running in the park.\"\n",
    "test3 = \"Their the ones who made a mistake.\"\n",
    "test4 = \"Its cold outside today.\"\n",
    "test5 = \"The baby was held by its mother.\"\n",
    "test6 = \"The book on AI really effected me.\"\n",
    "test7= \"The children love eating, coloring, and to play with their toys.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2eb715dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = test7 #\"I is reading about AI articles \"\n",
    "inputs = tokenizer(\"grammar:\"+text, truncation=True, return_tensors='pt')\n",
    "inputs.to(\"cuda:0\")\n",
    "\n",
    "output = model.generate(inputs['input_ids'], num_beams=5, max_length=512, early_stopping=True)\n",
    "correction=tokenizer.batch_decode(output, skip_special_tokens=True)\n",
    "result=(\"\".join(correction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ea2d2b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: The children love eating, coloring, and to play with their toys.\n",
      "\n",
      "corrected: Grammatik:The children love eating, coloring, and to play with their toys.\n"
     ]
    }
   ],
   "source": [
    "print(f\"input: {text}\\n\")\n",
    "print(f\"corrected: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d474ecea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p38)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
